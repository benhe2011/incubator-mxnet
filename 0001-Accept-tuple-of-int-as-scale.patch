From 097c10dbde13c264a70e479a1a74e596eb6961e4 Mon Sep 17 00:00:00 2001
From: Vandana Kannan <vandana268@gmail.com>
Date: Tue, 29 Jan 2019 17:08:20 -0800
Subject: [PATCH 01/11] Accept tuple of int as scale

---
 src/operator/nn/upsampling-inl.h | 50 +++++++++++++++++++++-----------
 src/operator/nn/upsampling.cc    | 22 +++++++++++---
 2 files changed, 51 insertions(+), 21 deletions(-)

diff --git a/src/operator/nn/upsampling-inl.h b/src/operator/nn/upsampling-inl.h
index feb44c894..cc389ba9a 100644
--- a/src/operator/nn/upsampling-inl.h
+++ b/src/operator/nn/upsampling-inl.h
@@ -48,7 +48,7 @@ enum UpSamplingMultiInputMode {kConcat, kSum};
 }  // namespace up_enum
 
 struct UpSamplingParam : public dmlc::Parameter<UpSamplingParam> {
-  int scale;
+  TShape scale;
   int num_filter;
   int sample_type;
   int num_args;
@@ -56,8 +56,10 @@ struct UpSamplingParam : public dmlc::Parameter<UpSamplingParam> {
   uint64_t workspace;
   DMLC_DECLARE_PARAMETER(UpSamplingParam) {
     DMLC_DECLARE_FIELD(scale)
-    .set_range(1, 1000)
-    .describe("Up sampling scale");
+    .set_default(TShape())
+    .describe("Up sampling scale. Integer or tuple of integers. "
+              "Different scale per dimension is allowed only for "
+              "nearest neighbor upsampling.");
     DMLC_DECLARE_FIELD(num_filter)
     .describe("Input filter. Only used by bilinear sample_type.")
     .set_default(0);
@@ -65,6 +67,11 @@ struct UpSamplingParam : public dmlc::Parameter<UpSamplingParam> {
     .add_enum("nearest", up_enum::kNearest)
     .add_enum("bilinear", up_enum::kBilinear)
     .describe("upsampling method");
+    DMLC_DECLARE_FIELD(num_args).set_default(1)
+    .describe("Number of inputs to be upsampled. For nearest neighbor "
+    "upsampling, this can be 1-N; the size of output will be"
+    "(scale*h_0,scale*w_0) and all other inputs will be upsampled to the"
+    "same size. For bilinear upsampling this must be 2; 1 input and 1 weight.");
     DMLC_DECLARE_FIELD(multi_input_mode)
     .add_enum("concat", up_enum::kConcat)
     .add_enum("sum", up_enum::kSum)
@@ -72,11 +79,6 @@ struct UpSamplingParam : public dmlc::Parameter<UpSamplingParam> {
     .describe("How to handle multiple input. concat means concatenate upsampled "
     "images along the channel dimension. sum means add all images together, "
     "only available for nearest neighbor upsampling.");
-    DMLC_DECLARE_FIELD(num_args).set_lower_bound(1)
-    .describe("Number of inputs to be upsampled. For nearest neighbor "
-    "upsampling, this can be 1-N; the size of output will be"
-    "(scale*h_0,scale*w_0) and all other inputs will be upsampled to the"
-    "same size. For bilinear upsampling this must be 2; 1 input and 1 weight.");
     DMLC_DECLARE_FIELD(workspace).set_default(512).set_range(0, 8192)
     .describe("Tmp workspace for deconvolution (MB)");
   }
@@ -102,7 +104,7 @@ void UpSamplingForward(const OpContext &ctx, const UpSamplingParam &param,
       Tensor<xpu, 4, DType> data = in_data[i].get<xpu, 4, DType>(s);
       int end = begin + data.size(1);
       int scale = out_data[up_enum::kOut].size(2)/in_data[i].size(2);
-      if (param.multi_input_mode == up_enum::kSum) {
+      /*if (param.multi_input_mode == up_enum::kSum) {
         if (i == 0) {
           Assign(out, req[up_enum::kOut], upsampling_nearest(data, scale));
         } else {
@@ -110,12 +112,12 @@ void UpSamplingForward(const OpContext &ctx, const UpSamplingParam &param,
         }
       } else {
         Assign(slice<1>(out, begin, end), req[up_enum::kOut], upsampling_nearest(data, scale));
-      }
+      }*/
       begin = end;
     }
   } else {
-    Tensor<xpu, 4, DType> data = in_data[up_enum::kData].get<xpu, 4, DType>(s);
-    Assign(out, req[up_enum::kOut], upsampling_nearest(data, param.scale));
+    /*Tensor<xpu, 4, DType> data = in_data[up_enum::kData].get<xpu, 4, DType>(s);
+    Assign(out, req[up_enum::kOut], upsampling_nearest(data, param.scale));*/
   }
 }
 
@@ -154,7 +156,7 @@ void UpSamplingBackward(const OpContext &ctx, const UpSamplingParam &param,
       }
       begin = end;
     }
-  } else {
+  } /*else {
     Tensor<xpu, 4, DType> input_grad = in_grad[up_enum::kData].get<xpu, 4, DType>(s);
     mshadow::Shape<2> in_shape = Shape2(input_grad.shape_[2], input_grad.shape_[3]);
     Assign(input_grad, req[up_enum::kData],
@@ -164,14 +166,28 @@ void UpSamplingBackward(const OpContext &ctx, const UpSamplingParam &param,
                                    param.scale,
                                    param.scale,
                                    param.scale));
-  }
+  }*/
 }
 
 static inline DeconvolutionParam GetDeconvolutionParam(const UpSamplingParam& param) {
   DeconvolutionParam p = DeconvolutionParam();
-  int kernel = 2 * param.scale - param.scale % 2;
-  int stride = param.scale;
-  int pad = static_cast<int>(ceil((param.scale - 1) / 2.));
+  int scale_h = 1;
+  int scale_w = 1;
+  if (param.scale.ndim() == 1) {
+    scale_h = param.scale[0];
+    scale_w = param.scale[0];
+  } else if (param.scale.ndim() == 2) {
+    scale_h = param.scale[0];
+    scale_w = param.scale[1];
+  } else if (param.scale.ndim() == 4) {
+    scale_h = param.scale[2];
+    scale_w = param.scale[3];
+  }
+  CHECK_EQ(scale_h, scale_w) <<
+  "UpSamplingBilinear: Scale should be the same along all dimensions for bilinear upsampling";
+  int kernel = 2 * scale_h - scale_h % 2;
+  int stride = scale_h;
+  int pad = static_cast<int>(ceil((scale_h - 1) / 2.));
   p.workspace = param.workspace;
   p.num_group = param.num_filter;
   p.num_filter = param.num_filter;
diff --git a/src/operator/nn/upsampling.cc b/src/operator/nn/upsampling.cc
index b6b3d873d..f73f9e938 100644
--- a/src/operator/nn/upsampling.cc
+++ b/src/operator/nn/upsampling.cc
@@ -37,13 +37,25 @@ static bool UpSamplingShape(const nnvm::NodeAttrs& attrs,
   CHECK_GE(in_shape->size(), 1U);
   const TShape &dshape = (*in_shape)[0];
   TShape oshape = dshape;
+  int scale_h = 1;
+  int scale_w = 1;
+  if (param_.scale.ndim() == 1) {
+    scale_h = param_.scale[0];
+    scale_w = param_.scale[0];
+  } else if (param_.scale.ndim() == 2) {
+    scale_h = param_.scale[0];
+    scale_w = param_.scale[1];
+  } else if (param_.scale.ndim() == 4) {
+    scale_h = param_.scale[2];
+    scale_w = param_.scale[3];
+  }
   if (param_.sample_type == up_enum::kNearest) {
     CHECK_EQ(in_shape->size(), static_cast<size_t>(param_.num_args));
     oshape[1] = 0;
     for (auto& shape : *in_shape) {
       CHECK_EQ(shape.ndim(), 4U) << \
         "UpSamplingNearest: Input data should be 4D in (batch, channel, y, x)";
-      int oh = dshape[2]*param_.scale, ow = dshape[3]*param_.scale;
+      int oh = dshape[2]*scale_h, ow = dshape[3]*scale_w;
       CHECK_EQ(oh%shape[2], 0U) << "UpSamplingNearest: input height of " << shape[2] << \
         "does not divide output height of " << oh;
       CHECK_EQ(ow%shape[3], 0U) << "UpSamplingNearest: input width of " << shape[3] << \
@@ -58,17 +70,19 @@ static bool UpSamplingShape(const nnvm::NodeAttrs& attrs,
     }
   } else {
     CHECK_EQ(in_shape->size(), 2U) << "Input:[data, weight]";
+    CHECK_EQ(scale_h, scale_w) <<
+    "UpSamplingBilinear: Scale should be the same along all dimensions for bilinear upsampling";
     CHECK_EQ(dshape.ndim(), 4U) << \
       "UpSamplingBilinear: Input data should be 4D in (batch, channel, y, x)";
     if (dshape.ndim() ==  0) return false;
-    int kernel = 2 * param_.scale - param_.scale % 2;
+    int kernel = 2 * scale_h - scale_h % 2;
     SHAPE_ASSIGN_CHECK(*in_shape,
         up_enum::kWeight,
         mshadow::Shape4(dshape[1], 1, kernel, kernel));
     oshape = dshape;
   }
-  oshape[2] = dshape[2] * param_.scale;
-  oshape[3] = dshape[3] * param_.scale;
+  oshape[2] = dshape[2] * scale_h;
+  oshape[3] = dshape[3] * scale_h;
   out_shape->clear();
   out_shape->push_back(oshape);
   return true;
-- 
2.20.1 (Apple Git-117)

